---
SPDX-License-Identifier: MIT
path: "/tutorials/kubernetes-on-hetzner-with-crio-flannel-and-hetzner-balancer"
slug: "kubernetes-on-hetzner-with-crio-flannel-and-hetzner-balancer"
date: "2025-01-13"
title: "Установка и настройка кластера Kubernetes на виртуальные машины облака Hetzner + Flannel + Ingress Nginx Controller + Hetzner TLS балансировщик"
short_description: "Это руководство содержит инструкции для установки кластера Kubernetes используя kubeadm and Helm"
tags: ["Kubernetes", "kubeadm", "Helm", "flannel", "CRI-O", "Nginx Ingress Controller", "Hetzner Balancer"]
author: "Dmitry Tiunov"
author_link: "https://github.com/DTiunov"
author_img: "https://avatars3.githubusercontent.com/u/....."
author_description: "DevOps инженер проектов PeakVisor и Zentist"
language: "ru"
available_languages: ["en", "ru"]
header_img: "header-x"
cta: "product"
---

## Вступление

Данное руководство содержит инструкции по установке кластера Kubernetes версии 1.30 используя [kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm) и [Helm](https://helm.
Предполагается, что все узлы кластера будут находится в одной локальной сети Hetzner, а запросы из Интернета к пользовательским приложениям будут осуществлятся через балансировщик нагрузки Hetzner. Данная конфигурация позволяет закрыть входящие соединения на узлы кластера, что делает кластер более безопасным.

На кластер будет установлен [Flannel](https://github.com/flannel-io/flannel) в качестве CNI (Container Network Interface) и [CRI-O](https://cri-o.io) в качестве CRI (Container Runtime Interface). 

Предпочтение CRI-O было отданно по следующим причинам:
* CRI-O более безопасен чем containerd поскольку имеет меньшее количество свойств и внутренних компонентов, что значительно снижает поверхность для атаки
* CRI-O имеет прозрачную структуру компонентов хранящуюся в открытом доступе
* У CRI-O активное сообщество 

В итоге, устанавливая компоненты шаг за шагом вы научитесь собирать кластер как конструктор и управлять балансировщиком нагрузки Hetzner используя аннотации заданные в values файле для Ingress Controller.

**Предварительные требования**

* 3 виртуальные машины в облаке Hetzner (одна для узла плоскости управления, две для рабочих узлов) с установленной на них операционной системой Ubuntu 24.04, подключенные к одной общей сети Hetzner
* [Helm](https://helm.sh/docs/intro/install) установленный на одну из виртуальных машин
* [Hetzner Cloud API токен](https://docs.hetzner.com/cloud/api/getting-started/generating-api-token) созданный внутри [Hetzner Cloud Console](https://console.hetzner.cloud)
* [TLS сертификат](https://docs.hetzner.com/konsoleh/ssl/certificates/#how-to-import-an-existing-certificate) импортированный в [Hetzner Cloud Console](https://console.hetzner.cloud)

## Шаг 1 - Подключение репозиториев

На этом шаге мы добавим Kubernetes и CRI-O репозитории на все узлы будующего кластера.

Устанавливаем версию Kubernetes как переменную окружения
```bash
KUBERNETES_VERSION=v1.30
```

Добавляем ключ и репозиторий Kubernetes
```bash
curl -fsSL https://pkgs.k8s.io/core:/stable:/$KUBERNETES_VERSION/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/$KUBERNETES_VERSION/deb/ /" | tee /etc/apt/sources.list.d/kubernetes.list
```

Добавляем ключ и репозиторий CRI-O
```bash
curl -fsSL https://pkgs.k8s.io/addons:/cri-o:/prerelease:/main/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/cri-o-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/prerelease:/main/deb/ /" | tee /etc/apt/sources.list.d/cri-o.list
```

## Шаг 2 - Установка пакетов

Здесь, мы установим пакеты CRI и компоненты Kubernetes на все узлы кластера.

Обновляет список доступных пакетов
```bash
apt update
```

Устанавливаем пакеты
```bash
apt install -y cri-o kubelet kubeadm kubectl
```

Отключаем автоматическое обновление для только что установленных пакетов
```bash
apt-mark hold kubelet kubeadm kubectl
```

## Шаг 3 - Настройка операционной системы

Kubernetes требует некоторых предварительных настроек операционной системы. Если вы используете образ Ubuntu24.04 предоставленный Hetzner, тогда вам не требуется отключать SWAP, так как он он выключен по умолчанию. Просто выполните команды ниже на всех узлах кластера.

Подключаем модуль ядра [br_netfilter](https://ebtables.netfilter.org/documentation/bridge-nf.html)
```bash
echo "br_netfilter" >> /etc/modules-load.d/modules.conf
```

Разрешаем переадресацию пакетов между разными сетями
```bash
sed -i 's/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g' /etc/sysctl.conf
```

Перезагружаем узел для применения настроек
```bash
reboot
```

## Шаг 4 - Инициализация кластера

Инициализация кластера выполняется на узле предназначенном для плоскости управления (Control Plane node). 

В данном руководстве предполагается использовать только 1 узел с ролью Control Plane, но если вы разворачиваете кластер в продуктивной среде, то для обеспечения должной отказоустойчивости рекомендуется использовать как минимум 3. 

Получаем конфигурационный файл инциализации со значениями по умолчанию
```bash
kubeadm config print init-defaults > InitConfiguration.yaml
```

Вам необходимо изменить следующие значения внутри файла:

* `bootstrapTokens.token: abcdef.0123456789abcdef` - вы можете получить токен начальной загрузки используя команду `kubeadm token list`
* `localAPIEndpoint.advertiseAddress: 10.0.0.1` - IP адрес вашего узла управления внутри локальной сети Hetzner
* `nodeRegistration.criSocket: unix:///var/run/crio/crio.sock` - путь к сокет-файлу CRI-O
* `nodeRegistration.kubeletExtraArgs.cloud-provider: external` - необходимо установить значение `external` для запуска с внешними облачными провайдерами
* `nodeRegistration.kubeletExtraArgs.node-ip: 10.0.0.1` - IP адрес вашего узла управлени внутри локальной сети Hetzner
* `nodeRegistration.name: your_host` - имя узла управления
* `apiServer.certSANs: [' your_host.example.com', '10.0.0.1']` - SAN (Subject Alternative Names) для сертификата API. Вы можете использовать несколько значений. Например FQDN и локальный IP адрес узла управления

Инициализируем кластер
```bash
kubeadm init --config InitConfiguration.yaml
```

## Шаг 5 - Присоединение узлов к кластеру

Now we can join nodes to the cluster. Run the commands below on each worker node.

Getting default join configuration file
```bash
kubeadm config print join-defaults > JoinConfiguration.yaml
```

Change the following values inside the file:

* `discovery.bootstrapToken.apiServerEndpoint: your_host.example.com:6443` - set your Control Plane node FQDN as the API endpoint
* `discovery.bootstrapToken.token: abcdef.0123456789abcdef` - the same like in [InitConfiguration.yaml file](#step-4---initializate-cluster)
* `discovery.tlsBootstrapToken: abcdef.0123456789abcdef` - the same like in [InitConfiguration.yaml file](#step-4---initializate-cluster)
* `nodeRegistration.criSocket: unix:///var/run/crio/crio.sock` - path to CRI-O socket file
* `nodeRegistration.kubeletExtraArgs.cloud-provider: external` - Set to `external` for running with an external cloud provider
* `nodeRegistration.kubeletExtraArgs.node-ip: 10.0.0.2` - the IP address of your Worker node in the Hetzner Network
* `nodeRegistration.name: your_host` - the name of the Worker node

Joining the node to the cluster
```bash
kubeadm join --config JoinConfiguration.yaml
```

Assign the worker role to worker nodes by adding the corresponding label. Run these commands on the Control Plane node
```bash
kubectl label node k8s-test-worker-1  node-role.kubernetes.io/worker=worker
kubectl label node k8s-test-worker-2  node-role.kubernetes.io/worker=worker
```

## Step 6 - Install CNI plugin

This guide uses [Flannel](https://github.com/flannel-io/flannel) as the CNI. If you want to use network policies to provide a higher level of security, you should consider other plugins.

Creating a namespace for Flannel
```bash
kubectl create ns kube-flannel
```

And adding privileges there. The `privileged` policy has no restrictions. All Pods in the kube-flannel namespace will be able to bypass typical container isolation mechanisms. For example, they will be able to access the node's network
```bash
kubectl label --overwrite ns kube-flannel pod-security.kubernetes.io/enforce=privileged
```

Adding helm repository
```bash
helm repo add flannel https://flannel-io.github.io/flannel/
```

You can get the values.yaml file from the [kube-flannel repository](https://github.com/flannel-io/flannel/blob/master/chart/kube-flannel/values.yaml) and set the value of `podCidr` to the same value as specified for `networking.podSubnet` in the [InitConfiguration.yaml file](#step-4---initializate-cluster).

Installing Flannel into the previously created namespace
```bash
helm install flannel flannel/flannel --values values.yaml -n kube-flannel
```

Components that specify `--cloud-provider=external` will add a taint `node.cloudprovider.kubernetes.io/uninitialized` with an effect `NoSchedule` during initialization. This marks the node as needing a second initialization from an external controller before it can be scheduled work. Note that in the event that a cloud controller manager is not available, new nodes in the cluster will be left unschedulable. That why we have to path CoreDNS after flannel installation to evade problems with CoreDNS Pods initialization
```bash
kubectl -n kube-system patch deployment coredns --type json -p '[{"op":"add","path":"/spec/template/spec/tolerations/-","value":{"key":"node.cloudprovider.kubernetes.io/uninitialized","value":"true","effect":"NoSchedule"}}]'
```

## Step 7 - Install Hetzner Cloud Controller

We need to install The Hetzner Cloud Controller manager to integrate our Kubernetes cluster with the Hetzner Cloud API. This will allow us to use the functions provided by the Hetzner. We will be mainly interested in Managed Load Balancer.

Creating a Kubernetes secret resource contains your Hetzner Cloud API token (see the Prerequisites in the [Introduction](#introduction)) and Hetzner Network ID. Hetzner Network ID can be extracted from the last digits in the URL of your Hetzner Cloud Network. For example, for the link https://console.hetzner.cloud/projects/98071/networks/2024666/resources it will be 2024666
```bash
kubectl -n kube-system create secret generic hcloud --from-literal=token=<HETZNER_API_TOKEN> --from-literal=network=<HETZNER_NETWORK_ID>
```

Adding and updating helm repository
```bash
helm repo add hcloud https://charts.hetzner.cloud
helm repo update hcloud
```

Install Hetzner Cloud Controller
```bash
helm install hccm hcloud/hcloud-cloud-controller-manager -n kube-system
```

## Step 8 - Install Ingress Controller

We will use [Nginx Ingress Controller](https://github.com/kubernetes/ingress-nginx) in this tutorial. TLS encryption will be done on the Hetzner Load Balancer, which will be automatically added and configured during the installation of the Ingress Controller.

Adding and updating helm repository
```bash
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update
```

The values.yaml file can be downloaded from the official [Ingress Nginx repository](https://github.com/kubernetes/ingress-nginx/blob/main/charts/ingress-nginx/values.yaml). Change the following values inside the file:

* `controller.dnsPolicy: ClusterFirstWithHostNet`
* `controller.hostNetwork: true`- by default, while using `hostNetwork`, name resolution uses the host's DNS. If you wish Ingress Controller to keep resolving names inside the Kubernetes network, use `ClusterFirstWithHostNet`
* `controller.kind: DaemonSet` - install Ingress Controller as a DaemonSet
* `controller.service.annotations` - these annotations define the settings for the Hetzner Load Balancer, which will be created by the Hetzner Сloud Сontroller automatically after the Ingress Controller is installed. The list and description of available annotations can be found in the official [Hetzner Cloud Controller repository]( https://github.com/hetznercloud/hcloud-cloud-controller-manager/blob/main/internal/annotation/load_balancer.go)
  * `load-balancer.hetzner.cloud/name: "k8s-test-lb"` - this is the name of the Load Balancer. The name will be visible in the Hetzner Cloud API console
  * `load-balancer.hetzner.cloud/location: "fsn1"` - specifies the location where the Load Balancer will be created in
  * `load-balancer.hetzner.cloud/type: "lb11"` - specifies the type of the Load Balancer
  * `load-balancer.hetzner.cloud/ipv6-disabled: "true"` - disables the use of IPv6 for the Load Balancer
  * `load-balancer.hetzner.cloud/network-zone: "your_network_name"` - specifies the Hetzner Network name where the Load Balancer will be created in. It must match the Hetzner Network of the Kubernetes nodes
  * `load-balancer.hetzner.cloud/use-private-ip: "true"` - configures the Load Balancer to use the private IP for Load Balancer server targets. This is necessary so that traffic from the Hetzner Balancer to the cluster nodes goes inside the Hetzner Network.
  * `load-balancer.hetzner.cloud/protocol: "https"` - specifies the protocol of the service
  * `load-balancer.hetzner.cloud/http-certificates: "certificatename"` - a comma separated list of IDs or Names of Certificates (see the Prerequisites in the [Introduction](#introduction))
  * `load-balancer.hetzner.cloud/http-redirect-http: "true"` - create a redirect from HTTP to HTTPS
* `controller.service.enableHttp: false` - enable the HTTP listener on both controller services or not
* `controller.service.targetPorts.https: http` - port of the Ingress Controller the external HTTP listener is mapped to. Since we have configured http to https redirect on the Hetzner Balancer and assigned it as responsible for TLS encryption, there is no need to use encryption between the Hetzner balancer and the cluster nodes. Accordingly, the port should be specified as http (80)


Installing Ingress Controller
```bash
helm install ingress-nginx-controller ingress-nginx/ingress-nginx -f values.yaml -n kube-system
```

## Step 9 - Install CSI driver  (Optional)

At the time of writing, Hetzner Cloud only has `ReadWriteOnce` volumes available via Container Storage Interface, but it can still be useful, so I recommend installing the CSI driver.

Adding and updating helm repository
```bash
helm repo add hcloud https://charts.hetzner.cloud
helm repo update hcloud
```

Installing Hetzner Cloud CSI driver
```bash
helm install hcloud-csi hcloud/hcloud-csi -n kube-system
```

## Conclusion

As a result, you have a cluster consisting of 1 Control Plane node and 2 Worker nodes. You also have the Load Balancer operating over HTTPs.

Now you can block all incoming Internet traffic with firewall rules on all cluster nodes and create the remaining resources necessary to run your own application on the cluster.

##### License: MIT

<!--

Contributor's Certificate of Origin

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I have
    the right to submit it under the license indicated in the file; or

(b) The contribution is based upon previous work that, to the best of my
    knowledge, is covered under an appropriate license and I have the
    right under that license to submit that work with modifications,
    whether created in whole or in part by me, under the same license
    (unless I am permitted to submit under a different license), as
    indicated in the file; or

(c) The contribution was provided directly to me by some other person
    who certified (a), (b) or (c) and I have not modified it.

(d) I understand and agree that this project and the contribution are
    public and that a record of the contribution (including all personal
    information I submit with it, including my sign-off) is maintained
    indefinitely and may be redistributed consistent with this project
    or the license(s) involved.

Signed-off-by: [submitter's name and email address here]

-->
