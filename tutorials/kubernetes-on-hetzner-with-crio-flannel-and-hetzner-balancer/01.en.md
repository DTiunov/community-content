---
SPDX-License-Identifier: MIT
path: "/tutorials/kubernetes-on-hetzner-with-crio-flannel-and-hetzner-balancer"
slug: "kubernetes-on-hetzner-with-crio-flannel-and-hetzner-balancer"
date: "2025-01-07"
title: "INSTALLING A KUBERNETES CLUSTER ON HETZNER CLOUD VIRTUAL MACHINES + FLANNEL + INGRESS NGINX CONTROLLER + HETZNER TLS BALANCER"
short_description: "This guide contains instructions for installing a Kubernetes cluster using kubeadm and Helm"
tags: ["Kubernetes", "kubeadm", "Helm", "flannel", "CRI-O", "Nginx Ingress Controller", "Hetzner Balancer"]
author: "Dmitry Tiunov"
author_link: "https://github.com/DTiunov"
author_img: "https://avatars3.githubusercontent.com/u/....."
author_description: "Manipulating arrays of characters in modern text editors that need more RAM than we used to fly to the moon. But it's super awesome..."
language: "en"
available_languages: ["en", "ru"]
header_img: "header-x"
cta: "product"
---

## Introduction

This guide contains instructions for installing a Kubernetes cluster version 1.30 using [kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm) and Helm. 
We will install [CRI-O](https://cri-o.io) as CRI (Container Runtime Interface) and [Flannel](https://github.com/flannel-io/flannel) as CNI (Container Network Interface). I chose CRI-O for several reasons:
* CRI-O is more secure than a container due to its limited set of features and internal components, which reduces the attack surface
* CRI-O has a clear component structure that is published
* CRI-O has many users and an active community

By installing the components step by step, you will assemble the cluster as a constructor. You will learn how to manage the Hetzner balancer using the annotations specified in the values ​​file for the Ingress Controller. All cluster nodes will be located within a single Hetzner network. Requests from the Internet to the cluster will be made through the Hetzner load balancer. This configuration allows you to close cluster nodes from external connections with a firewall. It makes your cluster more secure.

**Prerequisites**

* 3 virtual machines in the Hetzner Cloud (1 for Control Plane, 2 for Workers) with the Ubuntu 24.04 operating system and connected to the same Hetzner Network
* [Helm](https://helm.sh/docs/intro/install) installed on one of the virtual machines
* [Hetzner Cloud API token](https://docs.hetzner.com/cloud/api/getting-started/generating-api-token) in the [Hetzner Cloud Console](https://console.hetzner.cloud)
* [TLS certificate](https://docs.hetzner.com/konsoleh/ssl/certificates/#how-to-import-an-existing-certificate) imported into the [Hetzner Cloud Console](https://console.hetzner.cloud)

## Step 1 - Configure repositories

In this step we will add the Kubernetes and CRI-O repositories on all cluster nodes.

Setting the Kubernetes version as an environment variable

```bash
KUBERNETES_VERSION=v1.30
```

Adding Kubernetes key and repository
```bash
curl -fsSL https://pkgs.k8s.io/core:/stable:/$KUBERNETES_VERSION/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/$KUBERNETES_VERSION/deb/ /" | tee /etc/apt/sources.list.d/kubernetes.list
```

Adding CRI-O key and repository
```bash
curl -fsSL https://pkgs.k8s.io/addons:/cri-o:/prerelease:/main/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/cri-o-apt-keyring.gpg
echo "deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/prerelease:/main/deb/ /" | tee /etc/apt/sources.list.d/cri-o.list
```

## Step 2 - Install packages

Here we will install the Kubernetes CRI package to enable using OCI (Open Container Initiative) compatible runtimes, and Kubernetes cluster components on all nodes.

Updating list of available packages
```bash
apt update
```

Installing packages
```bash
apt install -y cri-o kubelet kubeadm kubectl
```

Disabling automatic updates for installed packages 
```bash
apt-mark hold kubelet kubeadm kubectl
```

## Step 3 - Operation System configuration

Kubernetes requires some preliminary operating system settings. If you are using the Ubuntu24.04 distribution provided by Hetzner, then you do not need to disable SWAP, just run the commands below on all nodes in the cluster.

Enabling [br_netfilter](https://ebtables.netfilter.org/documentation/bridge-nf.html) kernel module
```bash
echo "br_netfilter" >> /etc/modules-load.d/modules.conf
```

Enabling IP forward. It allows packets to be routed between different networks, enabling communication between subnets or acting as a gateway
```bash
sed -i 's/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g' /etc/sysctl.conf
```

Rebooting node to apply changes
```bash
reboot
```

## Step 4 - Initializate cluster

Cluster initialization is performed on the future Control Plane node. In our case, only 1 Control Plane node is assumed. To ensure fault tolerance in a production environment, you must use at least 3.

Getting default init configuration file
```bash
kubeadm config print init-defaults > InitConfiguration.yaml
```

Change the following values inside the file:

* `bootstrapTokens.token: abcdef.0123456789abcdef` - you can get bootstrap token by command `kubeadm token list`
* `localAPIEndpoint.advertiseAddress: 10.0.0.1` - the IP address of your Control Plane node in the Hetzner Network
* `nodeRegistration.criSocket: unix:///var/run/crio/crio.sock` - path to CRI-O socket file
* `nodeRegistration.kubeletExtraArgs.cloud-provider: external` - set to `external` for running with an external cloud provider
* `nodeRegistration.kubeletExtraArgs.node-ip: 10.0.0.1` - the IP address of your Control Plane node in the Hetzner Network
* `nodeRegistration.name: your_host` - the name of the Control Plane node
* `apiServer.certSANs: [' your_host.example.com', '10.0.0.1']` - Subject Alternative Names for API service certificate. It can be both, FQDN and local IP address of your Control Pane node

Initializing the cluster
```bash
kubeadm init --config InitConfiguration.yaml
```

## Step 5 - Join nodes into the cluster

Now we can join nodes to the cluster. Run the commands below on each worker node.

Getting default join configuration file
```bash
kubeadm config print join-defaults > JoinConfiguration.yaml
```

Change the following values inside the file:

* `discovery.bootstrapToken.apiServerEndpoint: your_host.example.com:6443` - set your master node FQDN as the API endpoint
* `discovery.bootstrapToken.token: abcdef.0123456789abcdef` - the same like in [InitConfiguration.yaml file](#step-4---initializate-cluster)
* `discovery.tlsBootstrapToken: abcdef.0123456789abcdef` - the same like in [InitConfiguration.yaml file](#step-4---initializate-cluster)
* `nodeRegistration.criSocket: unix:///var/run/crio/crio.sock` - path to CRI-O socket file
* `nodeRegistration.kubeletExtraArgs.cloud-provider: external` - Set to `external` for running with an external cloud provider
* `nodeRegistration.kubeletExtraArgs.node-ip: 10.0.0.2` - the IP address of your Worker node in the Hetzner Network
* `nodeRegistration.name: your_host` - the name of the Worker node

Joining the node to the cluster
```bash
kubeadm join --config JoinConfiguration.yaml
```

Assign the worker role to worker nodes by adding the corresponding label. Run these commands on the Control Plane node
```bash
kubectl label node k8s-test-worker-1  node-role.kubernetes.io/worker=worker
kubectl label node k8s-test-worker-2  node-role.kubernetes.io/worker=worker
```

## Step 6 - Install CNI plugin

This guide uses [Flannel](https://github.com/flannel-io/flannel) as the CNI. If you want to use network policies to provide a higher level of security, you should consider other plugins.

Creating a namespace for Flannel
```bash
kubectl create ns kube-flannel
```

And adding privileges there. The `privileged` policy has no restrictions. All Pods in the kube-flannel namespace will be able to bypass typical container isolation mechanisms. For example, they will be able to access the node's network
```bash
kubectl label --overwrite ns kube-flannel pod-security.kubernetes.io/enforce=privileged
```

Adding helm repository
```bash
helm repo add flannel https://flannel-io.github.io/flannel/
```

You can get the values.yaml file from the [kube-flannel repository](https://github.com/flannel-io/flannel/blob/master/chart/kube-flannel/values.yaml) and set the value of `podCidr` to the same value as specified for `networking.podSubnet` in the [InitConfiguration.yaml file](#step-4---initializate-cluster).

Installing Flannel into the previously created namespace
```bash
helm install flannel flannel/flannel --values values.yaml -n kube-flannel
```

Components that specify `--cloud-provider=external` will add a taint `node.cloudprovider.kubernetes.io/uninitialized` with an effect `NoSchedule` during initialization. This marks the node as needing a second initialization from an external controller before it can be scheduled work. Note that in the event that cloud controller manager is not available, new nodes in the cluster will be left unschedulable. That why we have to path CoreDNS after flannel installation to evade problems with CoreDNS Pods initialization
```bash
kubectl -n kube-system patch deployment coredns --type json -p '[{"op":"add","path":"/spec/template/spec/tolerations/-","value":{"key":"node.cloudprovider.kubernetes.io/uninitialized","value":"true","effect":"NoSchedule"}}]'
```

## Step 7 - Install Hetzner Cloud Controller

We need to install The Hetzner Cloud Controller manager to integrate our Kubernetes cluster with the Hetzner Cloud API. This will allow us to use the functions provided by the Hetzner. We will be mainly interested in managed load balancer.

Creating a Kubernetes secret resource contains your Hetzner Cloud API token (see the Prerequisites in the [Introduction](#introduction)) and Hetzner Network ID. Hetzner Network ID can be extracted from the last digits in the URL of your Hetzner Cloud Network. For example, for the link https://console.hetzner.cloud/projects/98071/networks/2024666/resources it will be 2024666
```bash
kubectl -n kube-system create secret generic hcloud --from-literal=token=<HETZNER_API_TOKEN> --from-literal=network=<HETZNER_NETWORK_ID>
```

Adding and updating helm repository
```bash
helm repo add hcloud https://charts.hetzner.cloud
helm repo update hcloud
```

Install Hetzner Cloud Controller
```bash
helm install hccm hcloud/hcloud-cloud-controller-manager -n kube-system
```

## Step 8 - Install Ingress Controller

## Step 9 - Install CSI driver  (Optional)

Instructions for a step that is not necessary to complete the tutorial, but can be helpful.

## Conclusion

A short conclusion summarizing what the user has done, and maybe suggesting different courses of action they can now take.

##### License: MIT

<!--

Contributor's Certificate of Origin

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I have
    the right to submit it under the license indicated in the file; or

(b) The contribution is based upon previous work that, to the best of my
    knowledge, is covered under an appropriate license and I have the
    right under that license to submit that work with modifications,
    whether created in whole or in part by me, under the same license
    (unless I am permitted to submit under a different license), as
    indicated in the file; or

(c) The contribution was provided directly to me by some other person
    who certified (a), (b) or (c) and I have not modified it.

(d) I understand and agree that this project and the contribution are
    public and that a record of the contribution (including all personal
    information I submit with it, including my sign-off) is maintained
    indefinitely and may be redistributed consistent with this project
    or the license(s) involved.

Signed-off-by: [submitter's name and email address here]

-->
